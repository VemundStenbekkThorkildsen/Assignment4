\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{refstyle}
\usepackage{wasysym}


\lstset{numbers=left,
	title=\lstname,
	numberstyle=\tiny, 
	breaklines=true,
	tabsize=4,
	language=Python,
	morekeywords={with,super,as},,
	frame=single,
	basicstyle=\footnotesize\tt,
	commentstyle=\color{comment},
	keywordstyle=\color{keyword},
	stringstyle=\color{string},
	backgroundcolor=\color{white},
	showstringspaces=false,
	numbers=left,
	numbersep=5pt,
	literate=
		{æ}{{\ae}}1
		{å}{{\aa}}1
		{ø}{{\o}}1
		{Æ}{{\AE}}1
		{Å}{{\AA}}1
		{Ø}{{\O}}1
	}

\usepackage{bm}
\usepackage{hyperref}
\usepackage[margin=1.25 in]{geometry}
\usepackage[usenames, dvipsnames]{color}
\usepackage{float}
\usepackage{commath}

\begin{document}
\begin{center}


{\LARGE\bf
FYS4150\\
\vspace{0.5cm}
Project 3, deadline October 25.
}
 \includegraphics[scale=0.075]{uio.png}\\
Author: Vemund Stenbekk Thorkildsen\\
\vspace{1cm}
{\LARGE\bf
Abstract
}\\
\end{center}
\newpage
{\LARGE\bf
Introduction
}\\
\noindent The Ising model in two dimensions will be studied and discussed in this report. The model is widely used, both in the study of phase transitions and statistics (source). In this report, the Ising model will be used to study phase transitions. In particular, the transition from a system with magnetic moment, to a system with zero magnetic moment. The Ising model predicts a phase shift at a given temperature. The system studied in this report will be a two dimensional lattice, where each lattice point only can take two different values. These values represent the spin, up-spin or down-spin, but can be represented in many ways. \\

\noindent The report will start off by an analytical solution for the case with a $2 \times 2$ lattice before moving on to solving this system numerically. This will be done by using the Metropolis algorithm. The results computed with the Metropolis algorithm will be compared to the analytic solutions. The main emphasis will be put on the Metropolis algorithm, its efficiency and precision (tror jeg).\\ 




{\LARGE\bf
Method
}\\

\noindent It is possible to derive an analytic solution for the simplest of the two dimensional case. Namely a $2 \times 2$ lattice with periodic boundary conditions. The partition dunction is given by:

\begin{equation}
Z= \sum\limits_{i=1}^{16}  e^{-J*E_{i}\beta}
\end{equation}

\noindent Where $\beta= \frac{1}{k_b T^2}$.  There are 16 different states of energy. Luckily, a lot of these yield the same result. Summing up all of these gives:

\begin{equation}
Z=2e^{-\beta 8 J}+2e^{\beta 8 J}+12
\end{equation}

\noindent The mean energy and magnetization is given by respectively:

\begin{equation}
E=\frac{1}{Z} \sum\limits_{i=1}^{16}  E_{i}e^{-J*E_{i}\beta}=\frac{-8e^{\beta 8J }+8e^{-\beta 8J}}{e^{-\beta 8 J}+e^{\beta 8 J}+6}
\end{equation}
and
\begin{equation}
M=\frac{1}{Z}\sum\limits_{i=1}^{16}  M_{i}e^{-J*E_{i}\beta}=\frac{4e^{\beta 8J}+8}{e^{-\beta 8 J}+e^{\beta 8 J}+6}
\end{equation}

\noindent The specific heat is given as the variance of energy divided by $k_b T^2$:

\begin{equation} 
c_v =\frac{64}{k_b T} \frac{1+3cosh(8\beta)}{(cosh(8\beta)+3)^2}
\end{equation}

\noindent The variance of magnetism divided by $k_b T$ reveals the susceptibility.

\begin{equation}
X=\frac{1}{k_b T} \Bigg(\frac{32^{\frac{8}{k_b T}}+32}{Z} - \Big(\frac{8e^{\frac{8}{k_b T}}+16}{Z}\Big)^2\Bigg)
\end{equation}

\noindent This problem will be solved by using the Metropolis algorithm. The algorithm can be described in ten steps. 

\begin{enumerate}
\item Establish an initial matrix with size $L \times L$ and compute the energy.
\item Position yourself at a random point in the lattice and flip one spin.
\item Compute the energy for this new state.
\item Compute $\vartriangle E$ 
\item If the energy is lowered, accept the new configuration and jump to step 9
\item If the energy is increased, compare $w=e^{-\beta \vartriangle E}$ with a random number.
\item If the random number is bigger than $w$, reject the new configuration and jump back to step 2.
\item If the random number is smaller or equal to $w$, accept the new configuration. 
\item Update expectation values
\item Repeat $L \times L$ times to let every lattice point get a chance to get picked.
\end{enumerate}
\hfill{Hjorth-Jensen., 2015}

\vspace{1cm}
\noindent This algorithm has a lot of steps, but computations for lower $L$ are quick. As stated earlier, one of the problems in this report will be to find a possible phase change. This will be done by computing for larger L. When increasing L, the computing time increases rapidly. To get a good result within the time-limit, the code has to be parallelized. This will be done by using MPI.\\

\noindent In order to find the critical temperature, it is possible to use this equation:

\begin{equation}
T_c(L)-T_c(L=\infty)=aL^{-\frac{1}{\nu}}
\end{equation} 

\noindent Where $L$ is the size of the lattice, $T_c$ is the critical temperature and $\nu$ is a constant equal to $1$. $T_c(L)$ is found graphically, so all we need to do is solve for $T_c(L=\infty)$ and $a$ numerically by using this equation


\begin{equation}
T_c(L)=T_c(L=\infty)+aL^{-\frac{1}{\nu}}
\end{equation}

This was done using the least squares rule for linear regression. 











 





\newpage
{\LARGE\bf
Results
}

\noindent The $2\times2$ matrix will serve as a benchmark to test the program in this report. This can be done as the analytic equations can be derived for this simple case.\\ 

\textbf{Table 1:} Mean energy and specific heat for $T=1.0$ \\
\centerline{
\begin{tabular}{c|c|c|c|c}
\hline
Monte Carlo cycles & Mean E random matrix & Mean E up matrix & $C_v$ random matrix & $C_v$ up matrix\\
\hline
$10^1$ & -8 & -8 & 0 & 0 \\
\hline
$10^2$ & -7.92079 & -8 &  0.627389 & 0 \\
\hline
$10^3$ &  -7.97602 & -7.97602 &  0.191233 & 0.0638722 \\
\hline
$10^4$ & -7.9808 & -7.984 &  0.121357 & 0.108604\\
\hline
$10^5$ & -7.98952 & -7.98424 & 0.13093 &  0.118817 \\
\hline
$10^6$ & -7.9836 & -7.98339 & 0.127234 & 0.128955 \\
\hline
Numerical & -7.9839 & -7.9839 & 0.1282 & 0.1282\\
\hline
\end{tabular}
}
\noindent The Mean energy moves quickly towards the analytic result. The mean is in fact accurate up to three leading digits even for $10^4$ monte carlo cycles for both a random matrix and a all up initial matrix. The specific heat in this case is the same as the variance ($C_v=\frac{Variance}{k_b T^2}$ with $ k_b T^2=1$)This property is more sensitive, and it is needed $10^6$ monte carlo cycles before reaching an accuracy of two leading digits for the random matrix, and three leading digits for the all up initial matrix. The results varied when running the program, which is to be expected for a probability influenced system. \\

\textbf{Table 2:} Mean absolute value of the magnetization and susceptibility for $T=1.0$\\
\centerline{
\begin{tabular}{c|c|c|c|c}
\hline
Monte Carlo cycles & Mean \abs{M} random matrix & Mean \abs{M} up matrix & $X$ random matrix & $X$ up matrix\\
\hline
$10^1$ & 4 & 4 & 0 & 0\\
\hline
$10^2$ & 3.94059 &3.9604 & 0.115283 & 0.156847\\
\hline
$10^3$ & 3.998 & 3.99401 & 0.00399201 & 0.0199441 \\
\hline
$10^4$ & 3.9952 & 3.9924 & 0.0127757 & 0.0239399 \\
\hline
$10^5$ & 3.99382 & 3.99396 & 0.0178416 & 0.0188433 \\
\hline
$10^6$ & 3.99456 & 3.9949 & 0.0164823 & 0.0150619 \\
\hline
Numerical & 3.9946 & 3.9946 & 0.0160 &0.0160\\
\hline
\end{tabular}
}
The results for magnetization and susceptibility tell much of the same story. The mean absolute value of the magnetization is accurate with three leading digits for  $10^3$ monte carlo cycles in both the random and all up case. As for the specific heat, the susceptibility is here equal to the variance of magnetism. The susceptibility is not stable before being computed with $10^6$ Monte Carlo cycles, and even then it is not accurate over two or one leading digits.


  
\newpage
\begin{figure} [H]
\centerline{
\includegraphics[scale=0.3]{avgEnergy1.jpg}
}
\caption{Development of average energy as a function of Monte Carlo cycles. Plotted at T=1.0 with an ordered and random matrix}
\label{fig:AverageEnergy1}
\end{figure}

\begin{figure} [H]
\centerline{
\includegraphics[scale=0.15]{RANDOMenergy1.jpg}
\includegraphics[scale=0.15]{UPenergy1.jpg}
}
\caption{Energy per cycle of random and all up initial configuration for $T=1$}
\label{fig:EnergyPerCycle1}
\end{figure}

\noindent It is clear to see in \figref{AverageEnergy1} and \figref{EnergyPerCycle1} that the energy quickly converges to a steady state around $-2$ per spin, or $-800$ for the entire system. For the all up initial configuration, it is already at this steady state (\figref{EnergyPerCycle1}). This equilibrium state is confined to a small number of energy levels, and after as low as $10^4$ cycles both seem to have reached the equilibrium. The nature of this low temperature system will be discussed later in the report. 




\begin{figure} [H]
\centerline{
\includegraphics[scale=0.3]{avgEnergy24.jpg}
}
\caption{Development of average energy as a function of Monte Carlo cycles. Plotted at T=2.4 with an ordered and random matrix}
\label{fig:AverageEnergy24}
\end{figure}

\begin{figure} [H]
\centerline{
\includegraphics[scale=0.15]{RANDOMenergy24.jpg}
\includegraphics[scale=0.15]{UPenergy24.jpg}
}
\caption{Energy per cycle of a random and all up initial matrix for $T=2.4$}
\label{fig:EnergyPerCycle24}
\end{figure}

\noindent For $T=2.4$ the energy also converges to an equilibrium state, but the energy fluctuates more than for lower temperature. This is to be expected, because there is more energy in the system, and will be elaborated further later in the report. The equilibrium is located at a higher energy than in \figref{AverageEnergy1}. As an effect of this, the all up initial matrix is not already at the energy equilibrium. After about $10^5$ cycles, it is safe to say that the equilibrium is reached (\figref{AverageEnergy24}).

\begin{figure} [H]
\centerline{
\includegraphics[scale=0.3]{avgMagn1.jpg}
}
\caption{Development of average absolute magnetization as a function of Monte Carlo cycles. Plotted at T=1.0 with an ordered and a random matrix}
\label{fig:AverageMagn1}
\end{figure}

\begin{figure} [H]
\centerline{
\includegraphics[scale=0.15]{RANDOMmag1notabs.jpg}
\includegraphics[scale=0.15]{RANDOMmag1abs.jpg}
}
\caption{Development of magnetization and absolute magnetization per cycle with random starting matrices for increasing Monte Carlo cycles.}
\label{fig:RandomMag1}
\end{figure}

\noindent As with the energy shown in \figref{AverageEnergy1}, the magnetization also converges quickly when the temperature is low (\figref{AverageMagn1}). It seems to have reached an equilibrium after $\approx 10^4$ cycles. The absolute magnetization behaves differently than the normal magnetization (\figref{RandomMagn1}). This difference is not possible to see in the energy plots, and indicates that there are more than one configuration that serve as an energy minimum. There is no point in including the all up initial matrices, as it is already an energy minimum of all spins pointing up, and the absolute value would yield the same result.  



\begin{figure} [H]
\centerline{
\includegraphics[scale=0.3]{avgMagn24.jpg}
}
\caption{Development of average absolute magnetization as a function of Monte Carlo cycles. Plotted at T=2.4 with an ordered and random matrix}
\label{fig:AverageMagn24}
\end{figure}

\begin{figure} [H]
\centerline{
\includegraphics[scale=0.15]{RANDOMmag24notabs.jpg}
\includegraphics[scale=0.15]{RANDOMmag24abs.jpg}
}
\caption{Development of magnetization and absolute magnetization per cycle with random starting matrices for increasing Monte Carlo cycles}
\label{fig:RandomMag24}
\end{figure}



\noindent As in the energy case for $T=2.4$, none of the initial configurations are at the equilibrium. After about $10^5$ Monte Carlo cycles they seem to have reached the equilibrium. When $T=2.4$ the magnetization fluctuates between being positive and negative (\figref{RandomMag24}) By looking at the absolute magnetization it soon becomes clear that the magnitude of the magnetization is limited to a finite range. The fluctuations are big, but this is to be expected, as there is more energy in the system. 

\begin{figure} [H]
\centerline{
\includegraphics[scale=0.245]{randomaccept.jpg}
}
\caption{Number of accepted configurations for a random initial matrix computed with $10^4$ Monte Carlo cycles for $T=1.0$ and $T=2.4$.}
\label{fig:RandomAccept}
\end{figure}

\begin{figure} [H]
\centerline{
\includegraphics[scale=0.245]{upaccept.jpg}
}
\caption{Number of accepted configurations for an all up initial matrix computed with $10^4$ Monte Carlo cycles for $T=1.0$ and $T=2.4$.}
\label{fig:UpAccept}
\end{figure}
\noindent The system with a random initial matrix at $T=1.0$ accepts many flips in the first few Monte Carlo cycles (\figref{RandomAccept}). This is because it initially is not at the equilibrium state. After it has reached equilibrium, it accepts far fewer moves, and follows the same pattern as \figref{UpAccept} for $T=1.0$. The total number of accepted configurations for the all up initial matrix at $T=1.0$ is the same as the accepted configurations for the random case after it has reached the equilibrium. The total number of accepted configurations is much higher when $T=2.4$, and the difference is negligible between the two. At this temperature, none of starting configurations are at the equilibrium, and will both accept many flips in the first cycles. 
 
\begin{figure} [H]
\centerline{
\includegraphics[scale=0.275]{accept.jpg}
}
\caption{Total number of accepted configurations as a function of temperature}
\label{fig:Accept}
\end{figure}
\noindent The number of configurations grows exponentially with temperature. The smooth nature of the all spins up initial matrix is contrasted by the graph for a random initial matrix. The uneven nature of this graph is a result of the random initial matrix. 


\begin{figure} [H]
\centerline{
\includegraphics[scale=0.15]{OccurancesRandom.jpg}
\includegraphics[scale=0.15]{OccurancesUp.jpg}
}
\caption{Probability distribution for T=2.4 for a random and an all up initial matrix.}
\label{fig:ProbBoth}
\end{figure}

\begin{figure} [H]
\centerline{
\includegraphics[scale=0.30]{ProbabilityRandomNew.jpg}
}
\caption{Probability distribution for varying temperature. Computed with $10^6$ Monte Carlo cycles.}
\label{fig:Probability}
\end{figure}

\begin{center}
\textbf{Table 3:} Variance in energy for different temperatures computed with a random matrix for different temperatures and $10^6$ Monte carlo cycles.
\end{center}
\centerline{
\begin{tabular}{|l|c|}
\hline
  Temperature & Variance\\
\hline
  T=1.0 & 10.1076\\
\hline
  T=1.25 & 52.9558\\
\hline
  T=1.50 & 181.261\\
\hline
  T=1.75 & 478.219\\
\hline
  T=2.0 & 1157.08\\
\hline 
  T=2.25 & 3145.36\\
\hline 
  T= 2.50 & 2479.22 \\
\hline 
  T=2.75 & 1690.69\\
\hline
  T=3.0 & 1445.91\\
\hline
\end{tabular}
}

\noindent The probability distribution shown in \figref{Probability} show that higher energies are to be expected when the temperature is increased. When the temperature is low, there are only a few possible energy states. This is in accordance with the energyplots in \figref{RandomEnergy} and \figref{UpEnergy}. The variance in table 3 is increasing up to $T=2.25$ before decreasing again. This is also shown in \figref{Probability}. The graph representing $T=2.25$ is much wider than all the other graphs. The probability distribution for $T=2.4$ is shown in \figref{ProbBoth}. The graph is skewed towards higher energies. WHY ARE THEY SKEWED?

For T mindre og lik 2.25 er de skewed positivt, og negativt for t større enn 2.25

  





\newpage
{\LARGE\bf
Discussion 
}

\noindent For the $2 \times 2$ case, the expection values showed distinct sensitivities (table 1,2). The mean energy and mean absolute magnetization converged quickly towards the analytic value. Both were accurate with three leading digits for as few as $10^4$ Monte Carlo cycles. When increasing the number of Monte Carlo cycles to $10^6$ the relative error decreases to a fraction of a $\permil$. The specific heat and susceptibility were both sensitive. The specific heat was accurate up to two or three leading digits, depending on the starting matrix, when computed with $10^6$ Monte Carlo cycles. The specific heat was accurate up to only one or two leading digits with $10^6$ Monte Carlo cycles. The program did not produce the same results for each run. This is due to the random nature of the system being examined.\\

\noindent The $20 \times 20$ case was studied with an emphasis on when the most likely state is reached. As shown in \figref{AverageEnergy1} and \figref{AverageMagn1} the graphs converge quickly towards an equilibrium when $T=1$. This is contrasted by the mean energy and mean absolute magnetization when the temperature is $2.4$(\figref{AverageEnergy24},\figref{AverageMagn24}). This system is governed by the Boltzmann distribution:

$$ e^{-\frac{\vartriangle E}{k_bT}}$$

\noindent To increase the energy, the random number used in the Monte Carlo test must be lower than $e^{-\frac{\vartriangle E}{k_bT}}$  (step 6). At low temperatures, the system will allow fewer energy increases compared to for higher temperatures. This results in faster converging towards the equilibrium for lower temperatures.\\

\noindent Another way to look at this is through a pure physical perspective. When there are high temperatures, by definition, there is more energy in the system. This will lead to more flips, and a higher degree of disorder. With less energy in the system, it is less likely to flip, hence faster converging to an equilibrium.\\

\noindent When starting with a random matrix, there are generally more flips (\figref{RandomAccept},\figref{UpAccept}). When the number of Monte Carlo cycles are increased, this difference becomes almost negligible. When the equilibrium is reached, the increase in accepted flips will behave in a similar fashion. This can be read out of \figref{RandomAccept} and \figref{UpAccept} for $T=1$, as after the first few cycles, the growth of accepted configurations grow at the same rate. For increasing temperature, the number of accepted configurations start growing exponentially. This true for both a random and ordered starting matrix, and is in line with what is to be expected, as the Boltzmann distribution has an exponential relation with temperature.(ER DETTE GREIT Å SKRIVE (skriv om uansett)).\\


\noindent The probability distribution for $T=2.4$ seem to have av negative skewness (right-modal)(\figref{ProbBoth}). This means that the majority of the energy occurrences happen to the left of the mean value. This again means that the system prefers to jump down in energy, which is to be expected,as it always wants to be at the lowest possible energy state. Another interesting thing to look at, is how the probability distribution behaves for different temperatures (\figref{Probability}). For lower temperatures, there are only a few lower energy levels that are are occurring frequently. The probability distributions are shifted towards higher energies as the temperatures increase. The distributions become wider moving towards the critical temperature, before narrowing again. This is mirrored by the variance shown in table 3. 


  








\newpage
{\LARGE\bf
Conclusion
}
















\newpage
{\LARGE\bf
Reference list
}\\
Hjort-Jensen,M., 2015. Computational physics, accessible at course github repository. 551 pages

\end{document}